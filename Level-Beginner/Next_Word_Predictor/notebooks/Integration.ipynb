{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be170756-5c79-47df-9e79-67414abcb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "from tensorflow.keras.models import load_model\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "model_3 = load_model(\"lstm_3word_800k_e75_final.keras\")\n",
    "model_2 = load_model(\"nextword_lstm_200k.keras\")\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c55d2fe2-d5c0-4d4b-98f8-ee522c9b11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "index_word = {v:k for k,v in word_index.items()}\n",
    "vocab = set(word_index.keys())\n",
    "import pickle\n",
    "pickle.dump(vocab, open(\"vocab.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9dc3fed-774f-4e2c-a8da-f1163b867f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trigram.pkl\", \"rb\") as f:\n",
    "    trigram_model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ada3b96b-217c-43d5-ac6f-417f024537a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(sentence):\n",
    "    for ch in string.punctuation:\n",
    "        sentence = sentence.replace(ch,\"\")\n",
    "    sentence = sentence.replace(\"\\t\",\"\")\n",
    "    sentence = sentence.lower()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72231c78-f923-4062-ada7-ef96fab9af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "904323d7-e98e-44b1-a3d8-391d7ffc96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedVocabSpellChecker:\n",
    "    \"\"\"\n",
    "    Optimized spellchecker with caching to avoid duplicate spell.correction() calls.\n",
    "    Key Optimization:\n",
    "    - correction_cache dictionary inside DP loop\n",
    "    - Checks cache before calling spell.correction()\n",
    "    - Reuses cached results for same substrings\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab):\n",
    "        \"\"\"Initialize with custom vocabulary\"\"\"\n",
    "        self.vocab = set(vocab)\n",
    "        self.spell = SpellChecker(language=None)  # Create empty spellchecker\n",
    "        self.spell.word_frequency.load_words(vocab)  # Load custom vocabulary\n",
    "    \n",
    "    def split_and_correct(self, token):\n",
    "        \"\"\"\n",
    "        Optimized: Cache spell corrections inside DP loop to reduce duplicate calls.\n",
    "        Returns:\n",
    "            list: List of corrected/split words\n",
    "        \"\"\"\n",
    "        n = len(token)\n",
    "        # dp[i] stores: (cost, word_list)\n",
    "        # cost = 0 for perfect match, increases with corrections\n",
    "        dp = [None] * (n + 1)\n",
    "        dp[0] = (0, [])\n",
    "        \n",
    "        # Cache for spell corrections to avoid duplicate calls\n",
    "        correction_cache = {}\n",
    "\n",
    "        for i in range(n):\n",
    "            if dp[i] is None:\n",
    "                continue\n",
    "            \n",
    "            current_cost, current_words = dp[i]\n",
    "            \n",
    "            # Try all possible pieces starting from position i\n",
    "            for j in range(i + 1, n + 1):\n",
    "                piece = token[i:j]\n",
    "                \n",
    "                # Case 1: Perfect match in vocab\n",
    "                if piece in self.vocab and (len(piece) >= 2 or piece in {\"i\", \"a\"}):\n",
    "                    new_cost = current_cost  # No penalty for perfect match\n",
    "                    new_words = current_words + [piece]\n",
    "                    \n",
    "                    if dp[j] is None or new_cost < dp[j][0]:\n",
    "                        dp[j] = (new_cost, new_words)\n",
    "                \n",
    "                # Case 2: Try spell correction (with caching)\n",
    "                elif len(piece) >= 3:\n",
    "                    # OPTIMIZATION: Check cache first to avoid duplicate spell.correction() calls\n",
    "                    if piece not in correction_cache:\n",
    "                        if piece in self.vocab:\n",
    "                            correction_cache[piece] = piece\n",
    "                        else:\n",
    "                            # Call spell.correction() only if not in cache\n",
    "                            corrected = self.spell.correction(piece)\n",
    "                            correction_cache[piece] = corrected if corrected else piece\n",
    "                    \n",
    "                    # Reuse cached correction\n",
    "                    corrected = correction_cache[piece]\n",
    "                    \n",
    "                    if corrected != piece and corrected in self.vocab:\n",
    "                        # Found a valid correction\n",
    "                        new_cost = current_cost + 1  # Add penalty for correction\n",
    "                        new_words = current_words + [corrected]\n",
    "                        \n",
    "                        if dp[j] is None or new_cost < dp[j][0]:\n",
    "                            dp[j] = (new_cost, new_words)\n",
    "\n",
    "        if dp[n] is not None:\n",
    "            return dp[n][1]\n",
    "        else:\n",
    "            # Last resort: try to correct the whole word\n",
    "            if token not in correction_cache:\n",
    "                corrected = self.spell.correction(token)\n",
    "                correction_cache[token] = corrected if corrected else token\n",
    "            return [correction_cache[token]]\n",
    "    \n",
    "    def splitWord(self, sentence):\n",
    "        \"\"\"\n",
    "        Main function to split and correct sentence.\n",
    "        Args:\n",
    "            sentence (str): Input sentence with potential misspellings\n",
    "        Returns:\n",
    "            str: Corrected and split sentence\n",
    "        \"\"\"\n",
    "        words = sentence.split()\n",
    "        new_words = []\n",
    "\n",
    "        for word in words:\n",
    "            if word in self.vocab:\n",
    "                new_words.append(word)\n",
    "            else:\n",
    "                new_words.extend(self.split_and_correct(word))\n",
    "\n",
    "        return \" \".join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "871c8eba-e9af-4cc6-b947-dda0e01c7859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love in you the\n",
      "you the\n",
      "i am\n"
     ]
    }
   ],
   "source": [
    "abc = OptimizedVocabSpellChecker(vocab)\n",
    "print(abc.splitWord(\"i loveinyouthe\"))\n",
    "print(abc.splitWord(\"youthe\"))\n",
    "print(abc.splitWord(\"iam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6eeba89e-b7d4-4571-8344-36ced428c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpellingCheck(sentence):\n",
    "    words = sentence.split()\n",
    "    corrected_words = []\n",
    "\n",
    "    for w in words:\n",
    "        if w in vocab:\n",
    "            corrected_words.append(w)\n",
    "        else:\n",
    "            correction = spell.correction(w)\n",
    "            corrected_words.append(correction if correction else w)\n",
    "\n",
    "    return \" \".join(corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9246ddfa-bcce-4cb7-8e57-20a82988eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_temperature(preds, temperature=1.0, k=3):\n",
    "    preds = np.log(preds + 1e-9) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    top_indices = preds.argsort()[-k:][::-1]\n",
    "    return top_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b1fd32d-1acd-41ab-b79f-a2bd6088cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_trigram(sentence, k=3):\n",
    "    words = sentence.lower().split()\n",
    "    \n",
    "    if len(words) < 2:\n",
    "        return []\n",
    "    \n",
    "    key = (words[-2], words[-1])\n",
    "    \n",
    "    if key not in trigram_model:\n",
    "        return []\n",
    "    \n",
    "    freq = Counter(trigram_model[key])\n",
    "    return [w for w, _ in freq.most_common(k)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dec60cca-6a32-407b-b74f-20a87941dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lstm2(sentence, k=3):\n",
    "    words = sentence.lower().split()\n",
    "    \n",
    "    if len(words) < 2:\n",
    "        return []\n",
    "    \n",
    "    w1, w2 = words[-2], words[-1]\n",
    "    \n",
    "    if w1 not in word_index or w2 not in word_index:\n",
    "        return []\n",
    "    \n",
    "    sequence = np.array([[word_index[w1], word_index[w2]]])\n",
    "    \n",
    "    preds = model_2.predict(sequence, verbose=0)[0]\n",
    "    \n",
    "    top_indices = sample_with_temperature(preds, temperature=0.7, k=k)\n",
    "    \n",
    "    return [index_word.get(i, \"\") for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b06e8208-55cf-4f44-acd6-40fcd433ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lstm3(sentence, k=3):\n",
    "    words = sentence.lower().split()\n",
    "    \n",
    "    if len(words) < 3:\n",
    "        return []\n",
    "    \n",
    "    w1, w2, w3 = words[-3], words[-2], words[-1]\n",
    "    \n",
    "    if any(w not in word_index for w in [w1, w2, w3]):\n",
    "        return []\n",
    "    \n",
    "    sequence = np.array([[word_index[w1], word_index[w2], word_index[w3]]])\n",
    "    \n",
    "    preds = model_3.predict(sequence, verbose=0)[0]\n",
    "    \n",
    "    top_indices = sample_with_temperature(preds, temperature=0.7, k=k)\n",
    "    \n",
    "    return [index_word.get(i, \"\") for i in top_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b2d6bd5-1b9f-4c89-8ab0-9ffda1c93200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tri: ['doing', 'going', 'talking']\n",
      "L2: ['we', 'get', 'have']\n",
      "L3: ['me', 'the', 'them']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tri:\", predict_trigram(\"what are you\"))\n",
    "print(\"L2:\", predict_lstm2(\"what are you doing\"))\n",
    "print(\"L3:\", predict_lstm3(\"what are you telling\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bdaefac-b7bf-4418-9fd9-b7630afdff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['know', 'be', 'see'] ['know', 'see', 'go'] ['i', 'im', 'you']\n"
     ]
    }
   ],
   "source": [
    "print(predict_lstm3(\"i want to\"),\n",
    "predict_lstm3(\"i need to\"),\n",
    "predict_lstm3(\"do you think\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59f8e2ac-267f-4e09-946a-c146f5823c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def merge_predictions(tri_preds, l2_preds, l3_preds, k=3):\n",
    "\n",
    "    scores = defaultdict(int)\n",
    "\n",
    "    # Weighting\n",
    "    for i, word in enumerate(l3_preds):\n",
    "        scores[word] += 3 - i   # higher rank = more weight\n",
    "\n",
    "    for i, word in enumerate(l2_preds):\n",
    "        scores[word] += 2 - i\n",
    "\n",
    "    for i, word in enumerate(tri_preds):\n",
    "        scores[word] += 1 - i\n",
    "\n",
    "    # Sort by score\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return [word for word, _ in ranked[:k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8e7212d0-9e77-48cf-a197-3e8869a49917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ultimate_predictor(sentence, k=3):\n",
    "    \"\"\"\n",
    "    Full pipeline: preprocess -> split -> spell check -> predict.\n",
    "\n",
    "    Priority order for next-word prediction:\n",
    "        1. lstm3  (primary - strongest context model)\n",
    "        2. trigram (secondary - reliable n-gram baseline)\n",
    "        3. lstm2  (tertiary - weaker, used only as tiebreaker)\n",
    "\n",
    "    Fallback logic:\n",
    "        - If lstm3 returns results, they anchor the final output.\n",
    "        - If lstm3 is empty/unavailable, trigram takes over as primary.\n",
    "        - lstm2 can only influence results when it AGREES with lstm3 or trigram.\n",
    "    \"\"\"\n",
    "    # --- Preprocessing pipeline ---\n",
    "    sentence = preProcess(sentence)\n",
    "    sentence = abc.splitWord(sentence)\n",
    "    sentence = SpellingCheck(sentence)\n",
    "\n",
    "    # --- Get predictions from all three sources ---\n",
    "    l3_preds  = predict_lstm3(sentence,   k=5)\n",
    "    tri_preds = predict_trigram(sentence, k=5)\n",
    "    l2_preds  = predict_lstm2(sentence,   k=5)\n",
    "\n",
    "    # --- Fallback chain: determine which source leads ---\n",
    "    # If lstm3 has no results, fall back to trigram-only\n",
    "    if not l3_preds and not tri_preds:\n",
    "        # Absolute fallback: just return whatever lstm2 has\n",
    "        return l2_preds[:k]\n",
    "\n",
    "    if not l3_preds:\n",
    "        # lstm3 failed: promote trigram to primary, allow lstm2 as secondary\n",
    "        primary   = tri_preds\n",
    "        secondary = l2_preds\n",
    "        # Return top-k from trigram, then fill with l2 that aren't duplicates\n",
    "        seen = set(primary[:k])\n",
    "        result = list(primary[:k])\n",
    "        for w in secondary:\n",
    "            if len(result) >= k:\n",
    "                break\n",
    "            if w not in seen:\n",
    "                result.append(w)\n",
    "                seen.add(w)\n",
    "        return result\n",
    "\n",
    "    # --- Normal path: all three sources available ---\n",
    "    # Suppress lstm2 predictions that don't appear in lstm3 OR trigram\n",
    "    # This prevents noisy lstm2 outputs from corrupting the final ranking\n",
    "    valid_context = set(l3_preds) | set(tri_preds)\n",
    "    filtered_l2 = [w for w in l2_preds if w in valid_context]\n",
    "\n",
    "    final_preds = merge_predictions(tri_preds, filtered_l2, l3_preds, k=k)\n",
    "\n",
    "    # --- Safety: if merge returns fewer than k, fill from lstm3 then trigram ---\n",
    "    seen = set(final_preds)\n",
    "    for w in (l3_preds + tri_preds):\n",
    "        if len(final_preds) >= k:\n",
    "            break\n",
    "        if w not in seen:\n",
    "            final_preds.append(w)\n",
    "            seen.add(w)\n",
    "\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0f53c50f-b822-4c05-8be0-a620d09d7795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', 'where', 'im']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultimate_predictor(\"What are you giong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b063a13-e525-4873-9119-c3f1de510ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e6c34-67d5-433b-827c-84a69f871a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
